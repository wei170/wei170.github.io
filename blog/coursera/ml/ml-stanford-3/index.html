<!doctype html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<title>Week 3 - Machine Learning - Guocheng&#39;s Space</title>
<meta name="description" content="Classification, Representation, Logistic Regression Model, Multiclass Classification">
<meta name="viewport" content="width=device-width, initial-scale=1">



  <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true
    },
    "HTML-CSS": { fonts: ["TeX"] }
  });
</script>
  <meta name="generator" content="Hugo 0.55.6" />
  
<meta itemprop="name" content="Week 3 - Machine Learning">
<meta itemprop="description" content="Classification, Representation, Logistic Regression Model, Multiclass Classification">


<meta itemprop="datePublished" content="2019-06-29T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2019-06-29T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="1496">



<meta itemprop="keywords" content="Machine Learning," />

  <meta property="og:title" content="Week 3 - Machine Learning" />
<meta property="og:description" content="Classification, Representation, Logistic Regression Model, Multiclass Classification" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://wei170.github.io/blog/coursera/ml/ml-stanford-3/" />
<meta property="article:published_time" content="2019-06-29T00:00:00&#43;00:00"/>
<meta property="article:modified_time" content="2019-06-29T00:00:00&#43;00:00"/>

  <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Week 3 - Machine Learning"/>
<meta name="twitter:description" content="Classification, Representation, Logistic Regression Model, Multiclass Classification"/>

  

  <link rel="stylesheet"
      href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/github.min.css">
  
    
      <link rel="stylesheet" href="/css/normalize.css">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Raleway:400,800,900|Source+Sans+Pro:400,700">
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/flag-icon-css/3.1.0/css/flag-icon.min.css">
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css">
      <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.10/css/all.css" integrity="sha384-+d0P83n9kaQMCwj8F4RJB66tzIwOKmrdb46+porD/OvrJ+37WqIM7UoBtwHO6Nlg" crossorigin="anonymous">
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.3.5/jquery.fancybox.min.css" />
      <link rel="stylesheet" href="/css/main.min.css">
      <link rel="stylesheet" href="/css/add-on.css">
    
  
    
      <link rel="stylesheet" href="/css/main.css">
    
  
    
      <link rel="stylesheet" href="/css/mathjax-style.css">
    
  
    
      <link rel="stylesheet" href="/css/code_snippet.css">
    
  
  
  
  
  
</head>

  <body>
    
<header id="site-header">
  <nav id="site-nav">
    <h1 class="nav-title">
      <a href="/">
        
          
            Blog
          
        
      </a>
    </h1>
    <menu id="site-nav-menu" class="flyout-menu">
      
        <a href="/" class="link"><i class="fas fa-home">&nbsp;</i>Home</a>
      
        <a href="/about/" class="link"><i class="far fa-id-card">&nbsp;</i>About</a>
      
        <a href="/blog/" class="link"><i class="far fa-newspaper">&nbsp;</i>Blog</a>
      
        <a href="/categories/" class="link"><i class="fas fa-sitemap">&nbsp;</i>Categories</a>
      
        <a href="/contact/" class="link"><i class="far fa-envelope">&nbsp;</i>Contact</a>
      
      <a href="#share-menu" class="share-toggle"><i class="fas fa-share-alt">&nbsp;</i>Share</a>
      

    </menu>
    

    <a href="#share-menu" class="share-toggle"><i class="fas fa-share-alt fa-2x">&nbsp;</i></a>
    <a href="#lang-menu" class="lang-toggle" lang="en"><span class="flag-icon flag-icon-en" alt="en"></span></a>
    <a href="#site-nav" class="nav-toggle"><i class="fas fa-bars fa-2x"></i></a>
  </nav>
  <menu id="lang-menu" class="flyout-menu">
  <a href="#" lang="en" class="active"><span class="flag-icon flag-icon-en" alt="en"></span></a>
  
    
      
    
      
        <a href="/cn" lang="cn" class="no-lang"><span class="flag-icon flag-icon-cn" alt="cn"></span></a>
      
    
  
</menu>

  
    <menu id="share-menu" class="flyout-menu">
      <h1>Share Post</h1>
      




  
    
    <a href="//twitter.com/share?text=Week%203%20-%20Machine%20Learning&amp;url=https%3a%2f%2fwei170.github.io%2fblog%2fcoursera%2fml%2fml-stanford-3%2f" target="_blank" rel="noopener" class="share-btn twitter">
        <i class="fab fa-twitter"></i><p>&nbsp;Twitter</p>
      </a>
  

  
      <a href="//www.facebook.com/sharer/sharer.php?u=https%3a%2f%2fwei170.github.io%2fblog%2fcoursera%2fml%2fml-stanford-3%2f" target="_blank" rel="noopener" class="share-btn facebook">
        <i class="fab fa-facebook"></i><p>&nbsp;Facebook</p>
        </a>
  

  
    <a href="//www.reddit.com/submit?url=https%3a%2f%2fwei170.github.io%2fblog%2fcoursera%2fml%2fml-stanford-3%2f&amp;title=Week%203%20-%20Machine%20Learning" target="_blank" rel="noopener" class="share-btn reddit">
          <i class="fab fa-reddit-alien"></i><p>&nbsp;Reddit</p>
        </a>
  

  
        <a href="//www.linkedin.com/shareArticle?url=https%3a%2f%2fwei170.github.io%2fblog%2fcoursera%2fml%2fml-stanford-3%2f&amp;title=Week%203%20-%20Machine%20Learning" target="_blank" rel="noopener" class="share-btn linkedin">
            <i class="fab fa-linkedin"></i><p>&nbsp;LinkedIn</p>
          </a>
  

  

  
        <a href="//www.pinterest.com/pin/create/button/?url=https%3a%2f%2fwei170.github.io%2fblog%2fcoursera%2fml%2fml-stanford-3%2f&amp;description=Week%203%20-%20Machine%20Learning" target="_blank" rel="noopener" class="share-btn pinterest">
          <i class="fab fa-pinterest-p"></i><p>&nbsp;Pinterest</p>
        </a>
  

  
        <a href="mailto:?subject=Check out this post by %7b%20%20%20%20%20%20%20%20map%5b%5d%7d&amp;body=https%3a%2f%2fwei170.github.io%2fblog%2fcoursera%2fml%2fml-stanford-3%2f" target="_blank" class="share-btn email">
          <i class="fas fa-envelope"></i><p>&nbsp;Email</p>
        </a>
  


    </menu>
  
</header>

    <div id="wrapper">
      <section id="site-intro">
  <a href="/"><img src="/img/main/avatar.jpg" class="circle" width="80" alt="avatar" /></a>
  <header>
    <h1>Guocheng Wei</h1>
  </header>
  <main>
    <p>I will share my side projects, paper readings, trending news, and my life here with you.</p>
  </main>
  
    <footer>
      <ul class="social-icons">
        

        <li><a href="//github.com/wei170" target="_blank" rel="noopener" title="GitHub" class="fab fa-github"></a></li>











<li><a href="//linkedin.com/in/wei170" target="_blank" rel="noopener" title="LinkedIn" class="fab fa-linkedin"></a></li>
























<li><a href="mailto:guochengwei170@gmail.com" target="_blank" title="Email" class="far fa-envelope"></a></li>

      </ul>
    </footer>
  
</section>

      <main id="site-main">
        <article class="post">
  <header>
  <div class="title">
    
        <h2><a href="/blog/coursera/ml/ml-stanford-3/">Week 3 - Machine Learning</a></h2>
    
    
        <p>Classification, Representation, Logistic Regression Model, Multiclass Classification</p>
    
</div>
  <div class="meta">
    <time class="published" datetime="2019-06-29 00:00:00 &#43;0000 UTC">
      June 29, 2019
    </time>
    <span class="author">Guocheng Wei</span>
    
        <p>8 minute read</p>
    
  </div>
</header>

  <section id="social-share">
    




  
    
    <a href="//twitter.com/share?text=Week%203%20-%20Machine%20Learning&amp;url=https%3a%2f%2fwei170.github.io%2fblog%2fcoursera%2fml%2fml-stanford-3%2f" target="_blank" rel="noopener" class="share-btn twitter">
        <i class="fab fa-twitter"></i><p>&nbsp;Twitter</p>
      </a>
  

  
      <a href="//www.facebook.com/sharer/sharer.php?u=https%3a%2f%2fwei170.github.io%2fblog%2fcoursera%2fml%2fml-stanford-3%2f" target="_blank" rel="noopener" class="share-btn facebook">
        <i class="fab fa-facebook"></i><p>&nbsp;Facebook</p>
        </a>
  

  
    <a href="//www.reddit.com/submit?url=https%3a%2f%2fwei170.github.io%2fblog%2fcoursera%2fml%2fml-stanford-3%2f&amp;title=Week%203%20-%20Machine%20Learning" target="_blank" rel="noopener" class="share-btn reddit">
          <i class="fab fa-reddit-alien"></i><p>&nbsp;Reddit</p>
        </a>
  

  
        <a href="//www.linkedin.com/shareArticle?url=https%3a%2f%2fwei170.github.io%2fblog%2fcoursera%2fml%2fml-stanford-3%2f&amp;title=Week%203%20-%20Machine%20Learning" target="_blank" rel="noopener" class="share-btn linkedin">
            <i class="fab fa-linkedin"></i><p>&nbsp;LinkedIn</p>
          </a>
  

  

  
        <a href="//www.pinterest.com/pin/create/button/?url=https%3a%2f%2fwei170.github.io%2fblog%2fcoursera%2fml%2fml-stanford-3%2f&amp;description=Week%203%20-%20Machine%20Learning" target="_blank" rel="noopener" class="share-btn pinterest">
          <i class="fab fa-pinterest-p"></i><p>&nbsp;Pinterest</p>
        </a>
  

  
        <a href="mailto:?subject=Check out this post by %7b%20%20%20%20%20%20%20%20map%5b%5d%7d&amp;body=https%3a%2f%2fwei170.github.io%2fblog%2fcoursera%2fml%2fml-stanford-3%2f" target="_blank" class="share-btn email">
          <i class="fas fa-envelope"></i><p>&nbsp;Email</p>
        </a>
  


  </section>
  
<a href="/blog/coursera/ml/ml-stanford-3/" class="image featured">
  <img src="/img/2019/06/ml_stanford_3.png" alt="ml stanford thumbnail">
</a>


  <div class="content">
    

<h1 id="classification">Classification</h1>

<p>Now we are switching from regression problems to classification problems. Don&rsquo;t be confused by the name &ldquo;Logistic Regression&rdquo;; it is named that way for historical reasons and is actually an approach to classification problems, <strong>not regression problems</strong>.</p>

<hr />

<h3 id="binary-classification-problem">Binary Classification Problem</h3>

<p>y can take on only two values, 0 and 1</p>

<hr />

<h3 id="hypothesis-representation">Hypothesis Representation</h3>

<p>We could approach the classification problem ignoring the fact that y is discrete-valued, and use our old linear regression algorithm to try to predict y given x. However, it is easy to construct examples where this method performs very poorly.</p>

<p>Hypothesis should satisfy:</p>

<p>$$0 \leq h_\theta(x) \leq 1$$</p>

<p><strong>Sigmoid Function</strong>, also called <strong>Logistic Function</strong>:</p>

<p>$$
h_\theta (x) = g ( \theta^T x ) \\
z = \theta^T x \\
g(z) = \dfrac{1}{1 + e^{-z}}
$$</p>

<p><a href="https://www.desmos.com/calculator/bgontvxotm">Sigmoid function</a></p>

<p>$h_\theta$ will give us the probability:</p>

<p>$$
h_\theta(x) = P(y=1 | x ; \theta) = 1 - P(y=0 | x ; \theta) \\
P(y = 0 | x;\theta) + P(y = 1 | x ; \theta) = 1
$$</p>

<p>Simplied probability function:</p>

<p>$$
P(y|x) = h_\theta(x)^{y} (1 - h_\theta(x))^{1-y}
$$</p>

<p>So in order to decease the cost:</p>

<p>$$
\begin{align}
\uparrow \log(P(y|x)) &amp; = \log(h_\theta(x)^{y} (1 - h_\theta(x))^{1-y}) \newline
&amp; = y \log(h_\theta(x)) + (1-y) \log(1 - h_\theta(x)) \newline
&amp; = - J(\theta) \downarrow
\end{align}
$$</p>

<hr />

<h3 id="decision-boundary">Decision Boundary</h3>

<p>The <strong>decision boundary</strong> is the line that separates the area where y = 0 and where y = 1.</p>

<p>$$
\begin{align}
h_\theta(x) &amp; \geq 0.5 \rightarrow y = 1 \newline
h_\theta(x) &amp; &lt; 0.5 \rightarrow y = 0 \newline
g(z) &amp; \geq 0.5 \quad when \; z \geq 0
\end{align}
$$</p>

<p>So:</p>

<p>$$
\begin{align}
\theta^T x &lt; 0 &amp; \Rightarrow y = 0 \newline
\theta^T x \geq 0 &amp; \Rightarrow y = 1
\end{align}
$$</p>

<hr />

<h3 id="cost-function">Cost Function</h3>

<p>We cannot use the same cost function that we use for linear regression because the Logistic Function will cause the output to be wavy, causing many local optima. In other words, it will not be a convex function.</p>

<p>Instead, our cost function for logistic regression looks like:</p>

<p>$$
\begin{align}
&amp; J(\theta) = \dfrac{1}{m} \sum_{i=1}^m \mathrm{Cost}(h_\theta(x^{(i)}),y^{(i)}) \newline
&amp; \mathrm{Cost}(h_\theta(x),y) = -\log(h_\theta(x)) \; &amp; \text{if y = 1} \newline
&amp; \mathrm{Cost}(h_\theta(x),y) = -\log(1-h_\theta(x)) \; &amp; \text{if y = 0}
\end{align}
$$</p>

<p>$J(\theta)$ vs. $h_\theta(x)$:</p>

<p>$$
\begin{align}
&amp; \text{ if } h_\theta(x) = y &amp; \mathrm{Cost}(h_\theta(x),y) = 0 \newline
&amp; \text{ if } y = 1 \; \mathrm{and} \; h_\theta(x) \rightarrow 0 &amp; \mathrm{Cost}(h_\theta(x),y) \rightarrow \infty \newline
&amp; \text{ if } y = 0 \; \mathrm{and} \; h_\theta(x) \rightarrow 1 &amp; \mathrm{Cost}(h_\theta(x),y) \rightarrow \infty \newline
\end{align}
$$</p>

<div style="text-align: center;">
    <img src="/img/2019/06/log_cost_func_y0.png" style="width: 300px !important;"/>
    <img src="/img/2019/06/log_cost_func_y1.png" style="width: 300px !important;"/>
</div>

<hr />

<h3 id="simplified-cost-function-and-gradient-descent">Simplified Cost Function and Gradient Descent</h3>

<p>Compress our cost function&rsquo;s two conditional cases into one case:</p>

<p>$$\mathrm{Cost}(h_\theta(x),y) = - y \; \log(h_\theta(x)) - (1 - y) \log(1 - h_\theta(x))$$</p>

<p>Entire cost function:</p>

<p>$$
J(\theta) = - \frac{1}{m} \sum_{i=1}^m[y^{(i)} log(h_\theta(x^{(i)})) + (1 - y^{(i)})log(1 - h_\theta(x^{(i)}))]
$$</p>

<p>A <strong>vectorized implementation</strong> is:</p>

<p>$$
\begin{align}
&amp; h = g(X\theta)\newline
&amp; J(\theta)  = \frac{1}{m} \cdot \left(-y^{T}\log(h)-(1-y)^{T}\log(1-h)\right)
\end{align}
$$</p>

<h4 id="gradient-descent">Gradient Descent</h4>

<p>This algorithm is <em>identical to the one we used in linear regression</em>. We still have to simultaneously update all values in theta.
$$
\begin{align}
&amp; Repeat \; \lbrace \newline
&amp; \; \theta_j := \theta_j - \frac{\alpha}{m} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)}) x_j^{(i)} \newline &amp; \rbrace
\end{align}
$$</p>

<p>In linear regression $h_\theta(x) = \theta^T x$, while in logistic regression $h_\theta(x) = \frac{1}{1 + e^{-\theta^T x}}$</p>

<p>A <strong>vectorized implementation</strong> is:</p>

<p>$$
\theta := \theta - \frac{\alpha}{m} X^T (g(X\theta) - \vec{y})
$$</p>

<h4 id="partial-derivative-of-j-θ">Partial derivative of J(θ)</h4>

<p>First calculate derivative of sigmoid function:</p>

<p>$$
\begin{align}
\sigma(x)&rsquo;&amp;=\left(\frac{1}{1+e^{-x}}\right)&lsquo;=\frac{-(1+e^{-x}) &lsquo;}{(1+e^{-x})^2}=\frac{-1&rsquo;-(e^{-x})&lsquo;}{(1+e^{-x})^2}=\frac{0-(-x)&lsquo;(e^{-x})}{(1+e^{-x})^2}=\frac{-(-1)(e^{-x})}{(1+e^{-x})^2}=\frac{e^{-x}}{(1+e^{-x})^2} \newline
&amp;=\left(\frac{1}{1+e^{-x}}\right)\left(\frac{e^{-x}}{1+e^{-x}}\right)=\sigma(x)\left(\frac{+1-1 + e^{-x}}{1+e^{-x}}\right)=\sigma(x)\left(\frac{1 + e^{-x}}{1+e^{-x}} - \frac{1}{1+e^{-x}}\right)=\sigma(x)(1 - \sigma(x))
\end{align}
$$</p>

<p>Resulting partial derivative:</p>

<p>$$
\begin{align}
\frac{\partial}{\partial \theta_j} J(\theta) &amp;= \frac{\partial}{\partial \theta_j} \frac{-1}{m}\sum_{i=1}^m \left [ y^{(i)} log (h_\theta(x^{(i)})) + (1-y^{(i)}) log (1 - h_\theta(x^{(i)})) \right ] \newline
&amp;= - \frac{1}{m}\sum_{i=1}^m \left [     y^{(i)} \frac{\partial}{\partial \theta_j} log (h_\theta(x^{(i)}))   + (1-y^{(i)}) \frac{\partial}{\partial \theta_j} log (1 - h_\theta(x^{(i)}))\right ] \newline
&amp;= - \frac{1}{m}\sum_{i=1}^m \left [     \frac{y^{(i)} \frac{\partial}{\partial \theta_j} h_\theta(x^{(i)})}{h_\theta(x^{(i)})}   + \frac{(1-y^{(i)})\frac{\partial}{\partial \theta_j} (1 - h_\theta(x^{(i)}))}{1 - h_\theta(x^{(i)})}\right ] \newline
&amp;= - \frac{1}{m}\sum_{i=1}^m \left [     \frac{y^{(i)} \frac{\partial}{\partial \theta_j} \sigma(\theta^T x^{(i)})}{h_\theta(x^{(i)})}   + \frac{(1-y^{(i)})\frac{\partial}{\partial \theta_j} (1 - \sigma(\theta^T x^{(i)}))}{1 - h_\theta(x^{(i)})}\right ] \newline
&amp;= - \frac{1}{m}\sum_{i=1}^m \left [     \frac{y^{(i)} \sigma(\theta^T x^{(i)}) (1 - \sigma(\theta^T x^{(i)})) \frac{\partial}{\partial \theta_j} \theta^T x^{(i)}}{h_\theta(x^{(i)})}   + \frac{- (1-y^{(i)}) \sigma(\theta^T x^{(i)}) (1 - \sigma(\theta^T x^{(i)})) \frac{\partial}{\partial \theta_j} \theta^T x^{(i)}}{1 - h_\theta(x^{(i)})}\right ] \newline
&amp;= - \frac{1}{m}\sum_{i=1}^m \left [     \frac{y^{(i)} h_\theta(x^{(i)}) (1 - h_\theta(x^{(i)})) \frac{\partial}{\partial \theta_j} \theta^T x^{(i)}}{h_\theta(x^{(i)})}   - \frac{(1-y^{(i)}) h_\theta(x^{(i)}) (1 - h_\theta(x^{(i)})) \frac{\partial}{\partial \theta_j} \theta^T x^{(i)}}{1 - h_\theta(x^{(i)})}\right ] \newline
&amp;= - \frac{1}{m}\sum_{i=1}^m \left [     y^{(i)} (1 - h_\theta(x^{(i)})) x^{(i)}_j - (1-y^{(i)}) h_\theta(x^{(i)}) x^{(i)}_j\right ] \newline
&amp;= - \frac{1}{m}\sum_{i=1}^m \left [     y^{(i)} (1 - h_\theta(x^{(i)})) - (1-y^{(i)}) h_\theta(x^{(i)}) \right ] x^{(i)}_j \newline
&amp;= - \frac{1}{m}\sum_{i=1}^m \left [     y^{(i)} - y^{(i)} h_\theta(x^{(i)}) - h_\theta(x^{(i)}) + y^{(i)} h_\theta(x^{(i)}) \right ] x^{(i)}_j \newline
&amp;= - \frac{1}{m}\sum_{i=1}^m \left [ y^{(i)} - h_\theta(x^{(i)}) \right ] x^{(i)}_j  \newline
&amp;= \frac{1}{m}\sum_{i=1}^m \left [ h_\theta(x^{(i)}) - y^{(i)} \right ] x^{(i)}_j
\end{align}
$$</p>

<hr />

<h3 id="multiclass-classification-one-vs-all">Multiclass Classification: One-vs-all</h3>

<p>$$
\begin{align}
&amp; h_\theta^{(i)}(x) = P(y = i | x; \theta) \quad i \in {0, 1, &hellip;, n} \newline
&amp; \mathrm{prediction} = \max_i( h_\theta ^{(i)}(x) )
\end{align}
$$</p>

<p><strong>To summarize</strong>:</p>

<ul>
<li>Train a logistic regression classifier $h_\theta(x)$ for each class￼ to predict the probability that ￼$y = i￼$.</li>
<li>To make a prediction on a new x, pick the class ￼that maximizes $h_\theta(x)$</li>
</ul>

<hr style="height: 10px; background-color:grey; opcaity: 0.3;"/>

<h1 id="regularization">Regularization</h1>

<h3 id="overfitting-and-underfitting">Overfitting and Underfitting</h3>

<p><strong>High bias</strong> or <strong>underfitting</strong>: when the form of our hypothesis function h maps poorly to the trend of the data.</p>

<p><strong>overfitting</strong> or <strong>high variance</strong>: caused by a hypothesis function that fits the available data but does not generalize well to predict new data. It is usually caused by a complicated function that creates a lot of unnecessary curves and angles unrelated to the data</p>

<p>There are two main options to address the issue of overfitting:</p>

<ol>
<li>Reduce the number of features:

<ul>
<li>Manually select which features to keep.</li>
<li>Use a model selection algorithm</li>
</ul></li>
<li>Regularization
*Keep all the features, but reduce the parameters $\theta_j$</li>
</ol>

<p>Regularization works well when we have a lot of slightly useful features.</p>

<hr />

<h3 id="regulated-linear-regression">Regulated Linear Regression</h3>

<h4 id="cost-function-1">Cost Function</h4>

<p>If we have overfitting from our hypothesis function, we can reduce the weight that some of the terms in our function carry by increasing their cost.</p>

<p>Say we wanted to make the following function more quadratic:</p>

<p>$\theta_0 + \theta_1x + \theta_2 x^2 + \theta_3 x^3 + \theta_4 x^4$</p>

<p>To penalize the influence $\theta_3x^3$ and $\theta_4x^4$:</p>

<p>$min_{\theta} \frac{1}{2m} \sum_{i=1}^m(h_{\theta}(x^{(i)}) - y^{(i)})^2 + 1000 \cdot \theta_3^2 + 1000 \cdot \theta_4^2$</p>

<p>Now, in order for the cost function to get close to zero, we will have to reduce the values of $\theta_3$ and $\theta_4$ to near zero, which in turn reduce the values of $\theta_3x^3$ and $\theta_4x^4$</p>

<p>We could also regularize all of our theta parameters in a single summation:</p>

<p>$$
min_{\theta} \frac{1}{2m} [\sum_{i=1}^m(h_{\theta}(x^{(i)}) - y^{(i)})^2 + \lambda \sum_{j=1}^n \theta_j^2]
$$</p>

<p>The $\lambda$, or lambda, is the <strong>regularization parameter</strong>. It determines how much the costs of our theta parameters are inflated.
You can visualize the effect of regularization in this interactive plot: <a href="https://www.desmos.com/calculator/1hexc8ntqp">https://www.desmos.com/calculator/1hexc8ntqp</a></p>

<h4 id="gradient-descent-1">Gradient Descent</h4>

<p>We will modify our gradient descent function to separate out $\theta_0$ from the rest of the parameters because we do not want to penalize $\theta_0$</p>

<p>$$
\begin{align}
  &amp; \text{Repeat}\ \lbrace \newline
  &amp; \ \ \ \ \theta_0 := \theta_0 - \alpha\ \frac{1}{m}\ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x_0^{(i)} \newline
  &amp; \ \ \ \ \theta_j := \theta_j - \alpha\ \left[ \left( \frac{1}{m}\ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)} \right) + \frac{\lambda}{m}\theta_j \right] &amp;\ \ \ \ \ \ \ \ \ \ j \in \lbrace 1,2&hellip;n\rbrace \newline
  &amp; \rbrace
\end{align}
$$</p>

<p>The term $\frac{\lambda}{m}\theta_j$ performs our regularization:</p>

<p>$ \theta_j := \theta_j(1 - \alpha\frac{\lambda}{m}) - \alpha\ \frac{1}{m}\ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)}$</p>

<p><strong>$1 - \alpha\frac{\lambda}{m}$ will always less than 1</strong></p>

<h4 id="normal-equation">Normal Equation</h4>

<p>Add in regularization:</p>

<p>$$
\begin{align}
  &amp; \theta = \left( X^TX + \lambda \cdot L \right)^{-1} X^Ty \newline
  &amp; \text{where}\ \ L =
  \begin{bmatrix}
    0 &amp; &amp; &amp; &amp; \newline
    &amp; 1 &amp; &amp; &amp; \newline
    &amp; &amp; 1 &amp; &amp; \newline
    &amp; &amp; &amp; \ddots &amp; \newline
    &amp; &amp; &amp; &amp; 1 \newline
  \end{bmatrix}
\end{align}
$$</p>

<p>$L$ is $(n+1)\times(n+1)$ to exclude $x_0$ with the top left 0.</p>

<p>Recall that if $m \leq n$, then $X^TX$ is non-invertible. However, when we add the term $\lambda \cdot L$, then $X^TX + lambda \cdot L$ becomes invertible.</p>

<hr />

<h3 id="regularized-logistic-regression">Regularized Logistic Regression</h3>

<h4 id="cost-function-2">Cost Function</h4>

<p>$$
J(\theta) = - \frac{1}{m} \sum_{i=1}^m[y^{(i)} log(h_\theta(x^{(i)})) + (1 - y^{(i)})log(1 - h_\theta(x^{(i)}))] + \frac{\lambda}{2m} \sum_{j=1}^n \theta_j^2
$$</p>

<p>$\sum_{j=1}^n \theta_j^2$ <strong>means to explicitly exclude</strong> the bias term, $\theta_0$</p>

<h4 id="grediant-descent">Grediant Descent</h4>

<p>$$
\begin{align}
  &amp; \text{Repeat}\ \lbrace \newline
  &amp; \ \ \ \ \theta_0 := \theta_0 - \alpha\ \frac{1}{m}\ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x_0^{(i)} \newline
  &amp; \ \ \ \ \theta_j := \theta_j - \alpha\ \left[ \left( \frac{1}{m}\ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)} \right) + \frac{\lambda}{m}\theta_j \right] &amp;\ \ \ \ \ \ \ \ \ \ j \in \lbrace 1,2&hellip;n\rbrace \newline
  &amp; \rbrace
\end{align}
$$</p>

<p>Looks identical to the gradient descent of the regularized linear regression, but here $h_\theta(x) = \frac{1}{1 + e^{-\theta^T x}}$ instead of $\theta^Tx$</p>

  </div>
  <footer>
    <ul class="stats">
  
    
    
      <li class="categories">
        <ul>
          
            
            <li><a class="article-category-link" href="https://wei170.github.io/categories/coursera-notes">Coursera Notes</a></li>
          
        </ul>
      </li>
    
  
  
    
    
      <li class="tags">
        <ul>
          
            
            <li><a class="article-category-link" href="https://wei170.github.io/tags/machine-learning">Machine Learning</a></li>
          
        </ul>
      </li>
    
  
</ul>

  </footer>
</article>
<article class="post">
  
    <article class="post">
        <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "guocheng-com" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    </article>


</article>
<div class="pagination">
  
    <a href="/blog/coursera/ml/ml-stanford-2/" class="button big previous"><i class="fas fa-angle-left"></i> Week 2 - Machine Learning</a>
  
  
    <a href="/blog/coursera/ml/ml-stanford-4/" class="button big next">Week 4 - Machine Learning <i class="fas fa-angle-right"></i></a>
  
</div>


      </main>
      <section id="site-sidebar">
  <section id="recent-posts">
    <header>
      <h1>Recent posts</h1>
    </header>
    
    <article class="mini-post">
      <section>
        
<a href="/blog/coursera/ml/ml-stanford-5/" class="image featured">
  <img src="/img/2019/07/ml_stanford_5.png" alt="ml stanford thumbnail">
</a>


      </section>
      <header>
        <h1><a href="/blog/coursera/ml/ml-stanford-5/">Week 5 - Machine Learning</a></h1>
        <time class="published" datetime="">July 3, 2019</time>
      </header>
    </article>
    
    <article class="mini-post">
      <section>
        
<a href="/blog/coursera/ml/ml-stanford-4/" class="image featured">
  <img src="/img/2019/07/ml_stanford_4.png" alt="ml stanford thumbnail">
</a>


      </section>
      <header>
        <h1><a href="/blog/coursera/ml/ml-stanford-4/">Week 4 - Machine Learning</a></h1>
        <time class="published" datetime="">July 1, 2019</time>
      </header>
    </article>
    
    <article class="mini-post">
      <section>
        
<a href="/blog/coursera/ml/ml-stanford-3/" class="image featured">
  <img src="/img/2019/06/ml_stanford_3.png" alt="ml stanford thumbnail">
</a>


      </section>
      <header>
        <h1><a href="/blog/coursera/ml/ml-stanford-3/">Week 3 - Machine Learning</a></h1>
        <time class="published" datetime="">June 29, 2019</time>
      </header>
    </article>
    
    <article class="mini-post">
      <section>
        
<a href="/blog/coursera/ml/ml-stanford-2/" class="image featured">
  <img src="/img/2019/06/ml_stanford_2.png" alt="ml stanford thumbnail">
</a>


      </section>
      <header>
        <h1><a href="/blog/coursera/ml/ml-stanford-2/">Week 2 - Machine Learning</a></h1>
        <time class="published" datetime="">June 28, 2019</time>
      </header>
    </article>
    
    <article class="mini-post">
      <section>
        
<a href="/blog/coursera/ml/ml-stanford-1/" class="image featured">
  <img src="/img/2019/06/ml_stanford_1.png" alt="ml stanford thumbnail">
</a>


      </section>
      <header>
        <h1><a href="/blog/coursera/ml/ml-stanford-1/">Week 1 - Machine Learning</a></h1>
        <time class="published" datetime="">June 27, 2019</time>
      </header>
    </article>
    
    
      <a href="/blog/" class="button">See more</a>
    
  </section>

  
    
      <section id="categories">
        <header>
          <h1><a href="/categories">Categories</a></h1>
        </header>
        <ul>
          
            
          
          
          <li>
            
              <a href="/categories/coursera-notes/">coursera-notes<span class="count">5</span></a>
            
          
          <li>
            
              <a href="/categories/project-overview/">project-overview<span class="count">1</span></a>
            
          
          <li>
            
              <a href="/categories/project-report/">project-report<span class="count">1</span></a>
            
          
          </li>
        </ul>
      </section>
    
  

  <section id="mini-bio">
    <header>
      <h1>About</h1>
    </header>
    <p>Passion in core network, ML, and software engineer. Love food, hiking, and snow skiing.</p>
    <footer>
      <a href="/about" class="button">Learn More</a>
    </footer>
  </section>
</section>

      <footer id="site-footer">
  
      <ul class="social-icons">
        

        <li><a href="//github.com/wei170" target="_blank" rel="noopener" title="GitHub" class="fab fa-github"></a></li>











<li><a href="//linkedin.com/in/wei170" target="_blank" rel="noopener" title="LinkedIn" class="fab fa-linkedin"></a></li>
























<li><a href="mailto:guochengwei170@gmail.com" target="_blank" title="Email" class="far fa-envelope"></a></li>

      </ul>
  
  <p class="copyright">
    
      &copy; 2019
      
        Guocheng&#39;s Space
      
    .
    Powered by <a href="//gohugo.io" target="_blank" rel="noopener">Hugo</a>
  </p>
</footer>
<a id="back-to-top" href="#" class="fas fa-arrow-up fa-2x"></a>

      
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/languages/html.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/languages/css.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/languages/js.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/languages/toml.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>


  
  <script src="https://code.jquery.com/jquery-3.3.1.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/skel/3.0.1/skel.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.3.5/jquery.fancybox.min.js"></script>
  <script src=/js/util.js></script>
  <script src=/js/main.js></script>
  <script src=/js/add-on.js></script>
  

  
    <script src="/js/code_snippet.js"></script>
  


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-92477600-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


    </div>
  </body>
</html>
